{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from src.dnn.loaders.VARdataloader import DataLoaderVAR as DataLoader\n",
    "\n",
    "PATH_EXP = \"/data/bacteria/experiments/autoencoders/6mer/26122023-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_encoder (InputLayer)  [(None, 64, 64, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 16)        160       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64, 64, 16)        64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64, 64, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32, 32, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32, 32, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " output_encoder (Dense)      (None, 100)               13107300  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13205412 (50.37 MB)\n",
      "Trainable params: 13204932 (50.37 MB)\n",
      "Non-trainable params: 480 (1.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder = tf.keras.models.load_model('/data/bacteria/experiments/autoencoders/6mer/26122023-2/models/encoder.keras')\n",
    "encoder =tf.keras.models.load_model(f\"{PATH_EXP}/models/encoder.keras\")\n",
    "# Show the model architecture\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PATH_EXP}/split-train-val-test.json\",\"r\") as fp:\n",
    "    datasets = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = datasets[\"id_labels\"][\"test\"][:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing of each FCGR to feed the model \n",
    "preprocessing = lambda x: x / x.max() \n",
    "\n",
    "# compute embeddings\n",
    "trainval_data = DataLoader(\n",
    "    list_paths=list_files,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    preprocessing=preprocessing,\n",
    "    inference_mode=True\n",
    ")\n",
    "\n",
    "# embeddings train+val\n",
    "embeddings = []\n",
    "for data in iter(trainval_data):\n",
    "    encoded_imgs = encoder(data).numpy()\n",
    "    embeddings.append(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "all_emb = np.concatenate(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 97.584114,   0.      ,   0.      , ...,   0.      , 486.8559  ,\n",
       "          0.      ],\n",
       "       [843.95386 , 723.7399  ,   0.      , ..., 183.53992 ,   0.      ,\n",
       "        142.3568  ],\n",
       "       [799.2456  , 286.15045 ,   0.      , ...,   0.      , 684.40643 ,\n",
       "        323.4834  ],\n",
       "       ...,\n",
       "       [849.60333 , 289.29495 ,   0.      , ...,   0.      , 674.723   ,\n",
       "        432.21732 ],\n",
       "       [  0.      , 359.7828  ,   0.      , ...,   0.      , 564.69556 ,\n",
       "          0.      ],\n",
       "       [772.81055 , 383.15405 ,   0.      , ...,   0.      , 483.15747 ,\n",
       "        407.27057 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_emb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
